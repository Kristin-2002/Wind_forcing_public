{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate NECC transport in INALT20 and observation along 23$^{\\circ}$W\n",
    "\n",
    "For both, model and observations we calculate the central position $ Y_{CM} $ and along-pathway intensity $ INT $ of zonal currents using the algorithm of Hsin (2012). \n",
    "\n",
    "\\begin{equation}\n",
    "Y_{CM}(x,t) = \\frac{\\int_{Z_l}^{Z_u} \\int_{Y_{S}}^{Y_{N}} y\\ u(x,y,z,t)\\ dy\\ dz}{\\int_{Z_l}^{Z_u} \\int_{Y_{S}}^{Y_{N}} u(x,y,z,t)\\ dy\\ dz}\n",
    "\\label{equ_Y_CM}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "INT(x,t) = \\int_{Z_l}^{Z_u} \\int_{Y_{CM}-W}^{Y_{CM}+W} u(x,y,z,t)\\ dy\\ dz \n",
    "\\label{equ_INT}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $y$ is latitude, $x$ is longitude, $u$ is zonal velocity, $z$ is depth, $t$ is time, $Z_u$ ($Z_l$) is upper (lower) boundary of the flow, $Y_N$ ($Y_S$) is northern (southern) limit of the flow, and $W$ is the half mean width of the flow.\n",
    "\n",
    "![](../figures/INALT20_obs_23w_comparison/1_INALT20_obs_23w_1999_2012.png)\n",
    "\n",
    "For transport calculation of the NECC we chose the following boundary conditions:\n",
    "\n",
    "$Z_u = 0\\,$m, $Z_l = 24.5\\,$kg$\\,$m$^{-3}$, $Y_N = 10^{\\circ}$N, $Y_S = 4^{\\circ}$S\n",
    "\n",
    "Based on monthly mean CORE climatology (INATL20_NECC_NECC_boundaries) we choose $W = 3.5^{\\circ}$ with max extent from 3$^{\\circ}$ to 10$^{\\circ}$N.\n",
    "\n",
    "The depth of the NECC core $Z_{CM}$ will be estimated similar to $Y_{CM}$:\n",
    "\n",
    "\\begin{equation}\n",
    "Z_{CM}(x,t) = \\frac{\\int_{Z_l}^{Z_u} \\int_{Y_{S}}^{Y_{N}} z\\ u(x,y,z,t)\\ dy\\ dz}{\\int_{Z_l}^{Z_u} \\int_{Y_{S}}^{Y_{N}} u(x,y,z,t)\\ dy\\ dz}\n",
    "\\label{equ_Z_CM}\n",
    "\\end{equation}\n",
    "\n",
    "Think about variable depth boundaries. Or boundaries define by density. Because is the model we calculate the NECC transport across the basin, not only at 23W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech preample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import dask\n",
    "import cmocean\n",
    "import datetime\n",
    "import nc_time_axis\n",
    "import cftime\n",
    "import time\n",
    "import seawater as sw\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask jobqueue and client\n",
    "To controle the resources used for parallel computations on computing nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_jobqueue\n",
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    # Dask worker size\n",
    "    cores=4, memory='24GB',\n",
    "    processes=1, # Dask workers per job\n",
    "    # SLURM job script things\n",
    "    queue='cluster', walltime='01:30:00',\n",
    "    # Dask worker network and temporary storage\n",
    "    interface='ib0', local_directory='$TMPDIR',\n",
    "    log_directory='./slurm_logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.18.4.13:42271</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.4.13:8787/status' target='_blank'>http://172.18.4.13:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.4.13:42271' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x7f26980f30a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(\n",
    "    minimum=1, maximum=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = 'INALT20_NECC_calc_transport'\n",
    "out_dir_data = Path('../data/'+script_name+'/')\n",
    "Path(out_dir_data).mkdir(parents=True, exist_ok=True)\n",
    "out_data_1 = 'INALT20_NECC_transport'\n",
    "\n",
    "out_dir_fig = Path('../figures/'+script_name+'/')\n",
    "Path(out_dir_fig).mkdir(parents=True, exist_ok=True)\n",
    "out_fig_1 = 'INALT20_'\n",
    "fig_format = '.png'\n",
    "\n",
    "savefig = 1; #set one if figures should be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters\n",
    "For INALT20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calc_JRA = 1 #set 1 if JRA should be recalculated\n",
    "run_calc_CORE = 0 #set 1 if CORE should be recalculated\n",
    "global_data_path = Path(\"/sfs/fs1/work-geomar1/smomw044/\")\n",
    "JRA_path = \"INALT20.L46-KFS10X\"\n",
    "exp_id = \"INALT20.L46-KFS10?\"\n",
    "\n",
    "CORE_path = \"shared/INALT20.L46-KFS044-S\"\n",
    "CORE_exp_id = \"INALT20.L46-KFS044\" # INALT COREv2\n",
    "\n",
    "temp_res = \"_5d_\" # 5d:5-daily; 1m:monthly; 1y:yearly; 1d:daily(stored currently on TAPE) \n",
    "nest_prefix = \"1_\" # \"1_\" for high resolution; leave empty for base model\n",
    "\n",
    "# chunk sizes\n",
    "chu_x = 100 # None means take the full dataset\n",
    "chu_y = 100\n",
    "chu_z = None\n",
    "chu_t = 1\n",
    "\n",
    "# variables wanted\n",
    "vars_want = ['vosaline','votemper','vozocrtx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of EUC - Boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlim = [-42, -17]\n",
    "latlim = [3, 10]\n",
    "zlim = [0, 100]\n",
    "\n",
    "## integers\n",
    "xclim1 = 549\n",
    "xclim2 = 1050\n",
    "yclim1 = 1690\n",
    "yclim2 = 1831\n",
    "\n",
    "p_ref = 0 # dbar; reference pressure for potential density calculation\n",
    "W = 3.5 #degN, half width of flow\n",
    "sigma_lim = [0,24.5] #kg/m^3, vertical boundaries of flow for INT [Z_u, Z_l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find relevant data files for INALT20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### Potential density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_to_str(latlim,lonlim):\n",
    "    lats_str=f'{abs(latlim[0])}s' if latlim[0] < 0 else f'{latlim[0]}n'\n",
    "    latn_str=f'{abs(latlim[1])}s' if latlim[1] < 0 else f'{latlim[1]}n'\n",
    "    lonw_str=f'{abs(lonlim[0])}w' if lonlim[0] < 0 else f'{lonlim[0]}e'\n",
    "    lone_str=f'{abs(lonlim[1])}w' if lonlim[1] < 0 else f'{lonlim[1]}e'\n",
    "    return lats_str,latn_str,lonw_str,lone_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pdens_sw(p_ref,ds):\n",
    "    \n",
    "    \"\"\" Calculates potential density using the EOS-80 seawater library\n",
    "    Parameters\n",
    "    ----------\n",
    "    pref : int\n",
    "    reference pressure for potential density calculation\n",
    "    ds : xr.DataSet containing NEMO3 model output\n",
    "      ds.deptht  : xr.DataArray (depth in m, positive downwards)\n",
    "      ds.gphit  : xr.DataArray (latitude grid in degN)\n",
    "      ds.vosaline  : xr.DataArray (practical salinity(eos 80))\n",
    "      ds.votemper  : xr.DataArray (potential temp (eos 80))\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "    Data array of potential density calculated using the EOS-80 seawater library [kg/m^3], same dimension as input data arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate pressure\n",
    "    p = xr.apply_ufunc(\n",
    "    sw.eos80.pres,\n",
    "    -abs(ds.deptht),ds.gphit,\n",
    "    dask='parallelized', output_dtypes=[float, ]\n",
    "    )\n",
    "    \n",
    "    # calculate in-situ temperature from potential temperature\n",
    "    t = xr.apply_ufunc(sw.eos80.temp,\n",
    "                       ds.vosaline,ds.votemper,p,p_ref,\n",
    "                       dask = 'parallelized',output_dtypes=[float,])\n",
    "    \n",
    "    # compute potential density\n",
    "    sig = xr.apply_ufunc(sw.eos80.pden,\n",
    "                         ds.vosaline,t,p,p_ref,\n",
    "                         dask = 'parallelized',output_dtypes=[float,])\n",
    "    sig -= 1000\n",
    "    \n",
    "    sig['tmask'] = ds.tmask\n",
    "    sig = sig.where(sig.tmask==1)\n",
    "    sig.name='sigma_%sm' %p_ref\n",
    "    sig.attrs['units']='kg/m^3'\n",
    "    sig.attrs['long_name']='Potential density'\n",
    "    sig.attrs['reference_pressure']= '%s dbar' %p_ref\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eastward transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eastw_transport(ucur,dy,dz,z_dim,y_dim):\n",
    "    ucur = ucur.where(ucur>=0)\n",
    "    trs_e = (dy*(ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)*1e-6\n",
    "    \n",
    "    trs_e.attrs['units']='Sv'\n",
    "    trs_e.attrs['long_name']='Eastward transport'\n",
    "    return trs_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y$_{CM}$ (central position of a current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YCM(ucur,sigma,lat,dy,dz,sigma_lim,z_dim,y_dim):\n",
    "    ucur = ucur.where((ucur>=0)&\n",
    "                      (sigma_lim[0]<=sigma)&\n",
    "                      (sigma<=sigma_lim[1]))\n",
    "    y_cm = (dy*(lat*ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)/(\n",
    "            dy*(ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)\n",
    "    \n",
    "    y_cm.attrs['units']='degN'\n",
    "    y_cm.attrs['name']='Y_CM'\n",
    "    y_cm.attrs['long_name'] = 'Central latitude'\n",
    "    return y_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z$_{CM}$ (core depth of a current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZCM(ucur,sigma,z,dy,dz,sigma_lim,z_dim,y_dim):\n",
    "    ucur = ucur.where((ucur>=0)&\n",
    "                      (sigma_lim[0]<=sigma)&\n",
    "                      (sigma<=sigma_lim[1]))\n",
    "    z_cm = (dy*(z*ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)/(\n",
    "            dy*(ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)\n",
    "    \n",
    "    z_cm.attrs['units']='m'\n",
    "    z_cm.attrs['name']='Z_CM'\n",
    "    z_cm.attrs['long_name'] = 'Central depth'\n",
    "    return z_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INT (eastward transport using cor following algorithm of Hsin 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eastw_INT(ucur,sigma,Y_CM,depth,lat,dy,dz,sigma_lim,W,z_dim,y_dim):\n",
    "    ucur = ucur.where(((ucur>0)&\n",
    "                      (sigma_lim[0]<=sigma)&\n",
    "                      (sigma<=sigma_lim[1])&\n",
    "                      (Y_CM-W < lat)&\n",
    "                      (Y_CM+W > lat)))\n",
    "    INT_e = (dy*(ucur*dz).sum(dim=z_dim)).sum(dim=y_dim,skipna=True)*1e-6\n",
    "    \n",
    "    INT_e.attrs['units']='Sv'\n",
    "    INT_e.attrs['name']='INT'\n",
    "    INT_e.attrs['long_name']='Eastward along-pathway intensity'\n",
    "    INT_e.attrs['history']='Eastward along-pathway intensity'\n",
    "    return INT_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_files = list(sorted(\n",
    "        (global_data_path/ JRA_path).glob(f\"{nest_prefix}[m,n]*.nc\")\n",
    "    ))\n",
    "\n",
    "aux_files\n",
    "\n",
    "with dask.config.set(scheduler='synchronous'):\n",
    "    ds_mesh = xr.open_dataset(\n",
    "            aux_files[0],\n",
    "            decode_cf=True,\n",
    "            chunks={\"t\":chu_t,\"z\":chu_z, \n",
    "                    \"y\":chu_y,\"x\":chu_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lonlim = [-42, -17]\n",
    "# latlim = [-3, 10]\n",
    "# zlim = [0, 400]\n",
    "\n",
    "# ## integers\n",
    "# xclim1 = 549\n",
    "# xclim2 = 1050\n",
    "# yclim1 = 1690\n",
    "# yclim2 = 1831\n",
    "# ds_mesh.gphit.sel(x=600,y=slice(1690,1831)).squeeze().values\n",
    "# ds_mesh.glamt.sel(y=1700,x=slice(549,1050)).squeeze().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_INALT20_calc_transp(JRA_files,ds_mesh,model_str,chu_x,chu_y,chu_z,chu_t,\n",
    "                             xclim1,xclim2,yclim1,yclim2,sigma_lim,p_ref,W_orig,\n",
    "                            latlim,lonlim):\n",
    "    with dask.config.set(scheduler='synchronous'):\n",
    "        ds_JRA_T = xr.open_dataset(\n",
    "            JRA_files[0],\n",
    "            chunks={\"time_counter\":chu_t,\n",
    "                     \"deptht\":chu_z, \n",
    "                     \"y\":chu_y, \n",
    "                     \"x\":chu_x},\n",
    "            decode_cf=True,\n",
    "            )\n",
    "    ds_JRA_T = ds_JRA_T.get(['vosaline','votemper'])\n",
    "\n",
    "    with dask.config.set(scheduler='synchronous'):\n",
    "        ds_JRA_U = xr.open_dataset(\n",
    "        JRA_files[1],\n",
    "        decode_cf=True,\n",
    "        chunks={\"time_counter\":chu_t,\n",
    "                 \"depthu\":chu_z, \n",
    "                 \"y\":chu_y, \n",
    "                 \"x\":chu_x},)\n",
    "\n",
    "\n",
    "    ## select region JRA\n",
    "    ds_JRA_T = ds_JRA_T.assign_coords(gphit=(['y','x'],ds_mesh.gphit.squeeze()))\n",
    "    ds_JRA_T = ds_JRA_T.assign_coords(glamt=(['y','x'],ds_mesh.glamt.squeeze()))\n",
    "    ds_JRA_T = ds_JRA_T.drop(['nav_lat','nav_lon'])\n",
    "\n",
    "    ds_JRA_U = ds_JRA_U.assign_coords(gphiu=(['y','x'],ds_mesh.gphiu.squeeze()))\n",
    "    ds_JRA_U = ds_JRA_U.assign_coords(glamu=(['y','x'],ds_mesh.glamu.squeeze()))\n",
    "    ds_JRA_U = ds_JRA_U.drop(['nav_lat','nav_lon'])\n",
    "\n",
    "    ds_JRA_U['e1u'] = (('y', 'x'), ds_mesh.e1u.squeeze())\n",
    "    ds_JRA_U['e2u'] = (('y', 'x'), ds_mesh.e2u.squeeze())\n",
    "    ds_JRA_U['e3u'] = (('depthu','y', 'x'), ds_mesh.e3u_0.squeeze())\n",
    "\n",
    "    ds_JRA_T.coords['tmask'] = ds_mesh.rename_dims({'z':'deptht'}).tmask.squeeze()\n",
    "    ds_JRA_U.coords['umask'] = ds_mesh.rename_dims({'z':'depthu'}).umask.squeeze()\n",
    "\n",
    "    ds_JRA_T = ds_JRA_T.sel(deptht=slice(0,400),\n",
    "                           x=slice(xclim1,xclim2),\n",
    "                           y=slice(yclim1,yclim2))\n",
    "\n",
    "    ds_JRA_U = ds_JRA_U.sel(depthu=slice(0,400),\n",
    "                           x=slice(xclim1,xclim2),\n",
    "                           y=slice(yclim1,yclim2))\n",
    "\n",
    "    # calculate density        \n",
    "    pdens_JRA = calc_pdens_sw(p_ref,ds_JRA_T)\n",
    "\n",
    "    ds_JRA_U = ds_JRA_U.isel(x=slice(0,-1)).swap_dims({'depthu':'depth'}\n",
    "                    ).rename({'depthu':'depth'})\n",
    "\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        # average on U-Grid\n",
    "        pdens_JRA =(pdens_JRA.isel(x=slice(None,-1))+pdens_JRA.isel(x=slice(1,None)))/2\n",
    "        # merge to one dataset\n",
    "        box_JRA = xr.merge([ds_JRA_U.vozocrtx.where(ds_JRA_U.umask==1),\n",
    "                    ds_JRA_U.e1u,\n",
    "                    ds_JRA_U.e2u,\n",
    "                    ds_JRA_U.e3u,\n",
    "                    pdens_JRA.swap_dims({'deptht':'depth'}\n",
    "                    ).rename({'deptht':'depth'})])\n",
    "    \n",
    "    # set coordinates and attributes\n",
    "    lon = box_JRA.glamu.isel(y=5)\n",
    "    box_JRA = box_JRA.assign_coords(lon=('x',lon))\n",
    "    lat = box_JRA.gphit.isel(x=400)\n",
    "    box_JRA = box_JRA.assign_coords(lat=('y',lat))\n",
    "    box_JRA = box_JRA.swap_dims({'x':'lon','y':'lat'}\n",
    "                     ).drop({'gphiu','gphit','glamu','time_centered'})\n",
    "    box_JRA.lat.attrs['units']='degN'\n",
    "    box_JRA.lat.attrs['long_name']='Latitude'\n",
    "    box_JRA.lon.attrs['units']='degE'\n",
    "    box_JRA.lon.attrs['long_name']='Longitude'\n",
    "    box_JRA.depth.attrs['units']='m'\n",
    "    box_JRA.depth.attrs['long_name']='Depth'\n",
    "\n",
    "    box_JRA.load()\n",
    "    lat_s,lat_n,lon_w,lon_e=coords_to_str(latlim,lonlim)\n",
    "\n",
    "    box_JRA.to_netcdf((out_dir_data / f\"{JRA_files[1].name[:-9]}lat{lat_s}{lat_n}_lon{lon_w}{lon_e}.nc\"),\n",
    "    engine='netcdf4',\n",
    "    encoding={'time_counter':{'units':'days since 1900-01-01 00:00:00'}})\n",
    "    time.sleep(10)\n",
    "\n",
    "    ## actual calulations\n",
    "    ds = box_JRA.sel(lat=slice(4,10))\n",
    "    Y_CM = YCM(ds.vozocrtx,ds.sigma_0m,ds.lat,ds.e2u,ds.e3u,sigma_lim,\n",
    "               'depth','lat')\n",
    "    Y_CM.attrs['lat_lim'] = '4degN to 10degN'\n",
    "    Y_CM.attrs['depth_lim'] = 'Z_u to Z_l (pot dens)'\n",
    "    Y_CM.attrs['Z_u'] = sigma_lim[0]\n",
    "    Y_CM.attrs['Z_u_name'] = 'Upper boundary of flow'\n",
    "    Y_CM.attrs['Z_u_unit'] = 'kg/m^3'\n",
    "    Y_CM.attrs['Z_l'] = sigma_lim[1]\n",
    "    Y_CM.attrs['Z_l_name'] = 'Lower boundary of flow'\n",
    "    Y_CM.attrs['Z_l_unit'] = 'kg/m^3'\n",
    "\n",
    "    Z_CM = ZCM(ds.vozocrtx,ds.sigma_0m,ds.depth,ds.e2u,ds.e3u,sigma_lim,\n",
    "               'depth','lat')\n",
    "    Z_CM.attrs['lat_lim'] = '4degN to 10degN'\n",
    "    Z_CM.attrs['depth_lim'] = 'Z_u to Z_l (pot dens)'\n",
    "    Z_CM.attrs['Z_u'] = sigma_lim[0]\n",
    "    Z_CM.attrs['Z_u_name'] = 'Upper boundary of flow'\n",
    "    Z_CM.attrs['Z_u_unit'] = 'kg/m^3'\n",
    "    Z_CM.attrs['Z_l'] = sigma_lim[1]\n",
    "    Z_CM.attrs['Z_l_name'] = 'Lower boundary of flow'\n",
    "    Z_CM.attrs['Z_l_unit'] = 'kg/m^3'\n",
    "\n",
    "    ds = box_JRA.sel(lat=slice(3,10),depth=slice(0,65))\n",
    "    T_fixed = eastw_transport(ds.vozocrtx,ds.e2u,ds.e3u,\n",
    "                              'depth','lat')\n",
    "    T_fixed.attrs['lat_lim'] = '3 to 10degN'\n",
    "    T_fixed.attrs['depth_lim'] = '0m to 65m'\n",
    "\n",
    "    INT = eastw_INT(box_JRA.vozocrtx,box_JRA.sigma_0m,Y_CM,ds.depth,box_JRA.lat,\n",
    "              box_JRA.e2u,box_JRA.e3u,sigma_lim,W,'depth','lat')\n",
    "    INT.attrs['lat_lim'] = 'Y_CM-W (min 3degN) to Y_CM+W (max 10degN)'\n",
    "    INT.attrs['W_name'] = 'Half mean width of flow'\n",
    "    INT.attrs['W_unit'] = 'degN'\n",
    "    INT.attrs['W'] = W\n",
    "    INT.attrs['depth_lim'] = 'Z_u to Z_l (pot dens)'\n",
    "    INT.attrs['Z_u'] = sigma_lim[0]\n",
    "    INT.attrs['Z_u_name'] = 'Upper boundary of flow'\n",
    "    INT.attrs['Z_u_unit'] = 'kg/m^3'\n",
    "    INT.attrs['Z_l'] = sigma_lim[1]\n",
    "    INT.attrs['Z_l_name'] = 'Lower boundary of flow'\n",
    "    INT.attrs['Z_l_unit'] = 'kg/m^3'\n",
    "\n",
    "    INT_25 = eastw_INT(box_JRA.vozocrtx,box_JRA.sigma_0m,Y_CM,ds.depth,box_JRA.lat,\n",
    "              box_JRA.e2u,box_JRA.e3u,[sigma_lim[0], 25.5],W,'depth','lat')\n",
    "    INT_25.attrs['lat_lim'] = 'Y_CM-W (min 3degN) to Y_CM+W (max 10degN)'\n",
    "    INT_25.attrs['W_name'] = 'Half mean width of flow'\n",
    "    INT_25.attrs['W_unit'] = 'degN'\n",
    "    INT_25.attrs['W'] = W_orig\n",
    "    INT_25.attrs['depth_lim'] = 'Z_u to Z_l (pot dens)'\n",
    "    INT_25.attrs['Z_u'] = sigma_lim[0]\n",
    "    INT_25.attrs['Z_u_name'] = 'Upper boundary of flow'\n",
    "    INT_25.attrs['Z_u_unit'] = 'kg/m^3'\n",
    "    INT_25.attrs['Z_l'] = 25.5\n",
    "    INT_25.attrs['Z_l_name'] = 'Lower boundary of flow'\n",
    "    INT_25.attrs['Z_l_unit'] = 'kg/m^3'\n",
    "\n",
    "\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        NECC_JRA = xr.merge([\n",
    "            Y_CM.rename('Y_CM'),Z_CM.rename('Z_CM'),\n",
    "            INT.rename('INT'),INT_25.rename('INT_25'),T_fixed.rename('T_fixed'),\n",
    "        ])\n",
    "\n",
    "\n",
    "    NECC_JRA.attrs['title'] = f'NECC transports in INALT20 {model_str}'\n",
    "    NECC_JRA.attrs['timeStamp'] = '%s' % datetime.now()\n",
    "    NECC_JRA.attrs['history'] = 'Original model output modified using INALT20_NECC_calc_transport.ipynb'\n",
    "\n",
    "    NECC_JRA.to_netcdf((out_dir_data / f\"{JRA_files[1].name[:-9]}{out_data_1}{'.nc'}\"),\n",
    "    engine='netcdf4',\n",
    "    encoding={'time_counter':{'units':'days since 1900-01-01 00:00:00'}})\n",
    "    return NECC_JRA,box_JRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 187, in read\n",
      "    n_frames = await stream.read_bytes(8)\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 489, in wait_for\n",
      "    fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 491, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n",
      "distributed.core - ERROR - Exception while handling op retire_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 187, in read\n",
      "    n_frames = await stream.read_bytes(8)\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 489, in wait_for\n",
      "    fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 491, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n",
      "distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 489, in wait_for\n",
      "    fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/asyncio/tasks.py\", line 491, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/deploy/adaptive.py\", line 187, in scale_down\n",
      "    await self.scheduler.retire_workers(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 787, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 657, in send_recv\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/gxfs_home/geomar/smomw294/miniconda3/envs/xorca_env/lib/python3.9/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n",
      "distributed.deploy.adaptive_core - ERROR - Adaptive stopping due to error Timed out during handshake while connecting to tcp://172.18.4.185:42507 after 10 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "CPU times: user 13min 50s, sys: 3min 32s, total: 17min 22s\n",
      "Wall time: 1h 10min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for restr_years in range(2007,2019):\n",
    "    print (restr_years)\n",
    "    # JRA\n",
    "    JRA_files = list(sorted(\n",
    "        (global_data_path / JRA_path ).glob(\n",
    "            f\"{nest_prefix}{exp_id}{temp_res}{restr_years}????_{restr_years}????_grid_[T,U].nc\")\n",
    "    ))\n",
    "\n",
    "    NECC_JRA,box_JRA = load_INALT20_calc_transp(JRA_files,ds_mesh,'JRA',chu_x,chu_y,chu_z,chu_t,\n",
    "                        xclim1,xclim2,yclim1,yclim2,sigma_lim,p_ref,W,\n",
    "                        latlim,lonlim)\n",
    "    time.sleep(10) \n",
    "\n",
    "    # CORE\n",
    "    if restr_years<2010:\n",
    "        CORE_files = list(sorted(\n",
    "            (global_data_path / CORE_path ).glob(\n",
    "                f\"{nest_prefix}{CORE_exp_id}{temp_res}{restr_years}????_{restr_years}????_grid_[T,U].nc\"\n",
    "            )))\n",
    "        NECC_CORE,box_CORE = load_INALT20_calc_transp(CORE_files,ds_mesh,'CORE',chu_x,chu_y,chu_z,chu_t,\n",
    "                            xclim1,xclim2,yclim1,yclim2,sigma_lim,p_ref,W,\n",
    "                            latlim,lonlim)\n",
    "        time.sleep(10)\n",
    "\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xorca_env]",
   "language": "python",
   "name": "conda-env-xorca_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
